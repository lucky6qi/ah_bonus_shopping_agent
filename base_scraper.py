"""Base scraper class for AH.nl - supports multiple product categories"""
import json
import time
import os
from abc import ABC, abstractmethod
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import requests


class BaseAHScraper(ABC):
    """Base scraper class for AH.nl - can be extended for different categories"""
    
    def __init__(self, config, category_name: str, base_url: str):
        """
        åˆå§‹åŒ–åŸºç¡€scraper
        
        Args:
            config: Configå¯¹è±¡
            category_name: å“ç±»åç§°ï¼ˆå¦‚ "bonus", "groente", "vlees"ç­‰ï¼‰
            base_url: è¯¥å“ç±»çš„URL
        """
        self.config = config
        self.category_name = category_name
        self.base_url = base_url
        self.driver = None
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        
        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
        self.cache_file = f"products_cache_{category_name}.json"
    
    def _load_cache(self) -> Optional[List[Dict[str, Any]]]:
        """Load products from cache if valid"""
        if not os.path.exists(self.cache_file):
            return None
        
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # Check if cache has timestamp
            if isinstance(cache_data, dict) and 'timestamp' in cache_data:
                cache_time = datetime.fromisoformat(cache_data['timestamp'])
                expiry_time = cache_time + timedelta(hours=self.config.cache_expiry_hours)
                
                if datetime.now() < expiry_time:
                    print(f"âœ… Using cached {self.category_name} products (cached at {cache_time.strftime('%Y-%m-%d %H:%M:%S')})")
                    return cache_data.get('products', [])
                else:
                    print(f"â„¹ï¸ Cache expired (expired at {expiry_time.strftime('%Y-%m-%d %H:%M:%S')})")
                    return None
            else:
                return None
                
        except Exception as e:
            print(f"âš ï¸ Error loading cache: {e}")
            return None
    
    def _save_cache(self, products: List[Dict[str, Any]]):
        """Save products to cache with timestamp"""
        try:
            cache_data = {
                'timestamp': datetime.now().isoformat(),
                'category': self.category_name,
                'products': products
            }
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… {self.category_name} products cached to {self.cache_file}")
        except Exception as e:
            print(f"âš ï¸ Error saving cache: {e}")
    
    def delete_cache(self):
        """Delete cache file completely"""
        if os.path.exists(self.cache_file):
            try:
                os.remove(self.cache_file)
                print(f"ðŸ—‘ï¸  Deleted cache file: {self.cache_file}")
            except Exception as e:
                print(f"âš ï¸ Error deleting cache file: {e}")
    
    def _setup_driver(self):
        """Setup Chrome driver"""
        if self.driver:
            return
            
        chrome_options = Options()
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        # ä¸resizeçª—å£ï¼Œä¿æŒé»˜è®¤å¤§å°
    
    def _accept_cookies(self):
        """Accept cookies - common method for all scrapers"""
        print("ðŸª Looking for cookie consent dialog...")
        
        accept_selectors = [
            "//button[@data-testid='accept-cookies']",
            "//button[contains(text(), 'Accepteren')]",
            "//button[contains(text(), 'Accept')]",
        ]
        
        for selector in accept_selectors:
            try:
                cookie_button = WebDriverWait(self.driver, 3).until(
                    EC.element_to_be_clickable((By.XPATH, selector))
                )
                self.driver.execute_script("arguments[0].scrollIntoView(true);", cookie_button)
                time.sleep(0.5)
                cookie_button.click()
                print("âœ… Cookies accepted")
                time.sleep(1)
                return True
            except:
                continue
        
        print("âš ï¸ Cookie banner not found or could not be accepted - continuing anyway")
        return False
    
    @abstractmethod
    def _try_lightweight_scrape(self) -> Optional[List[Dict[str, Any]]]:
        """
        å°è¯•ä½¿ç”¨è½»é‡çº§æ–¹æ³•æŠ“å–ï¼ˆrequests + BeautifulSoupï¼‰
        å­ç±»éœ€è¦å®žçŽ°è¿™ä¸ªæ–¹æ³•
        
        Returns:
            äº§å“åˆ—è¡¨ï¼Œå¦‚æžœå¤±è´¥è¿”å›žNone
        """
        pass
    
    @abstractmethod
    def _scrape_with_selenium(self) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨SeleniumæŠ“å–ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
        å­ç±»éœ€è¦å®žçŽ°è¿™ä¸ªæ–¹æ³•
        
        Returns:
            äº§å“åˆ—è¡¨
        """
        pass
    
    @abstractmethod
    def _extract_product_from_element(self, element) -> Optional[Dict[str, Any]]:
        """
        ä»ŽHTMLå…ƒç´ ä¸­æå–äº§å“ä¿¡æ¯
        å­ç±»éœ€è¦å®žçŽ°è¿™ä¸ªæ–¹æ³•
        
        Args:
            element: Selenium WebElementæˆ–BeautifulSoupå…ƒç´ 
        
        Returns:
            äº§å“å­—å…¸ï¼Œå¦‚æžœæå–å¤±è´¥è¿”å›žNone
        """
        pass
    
    def scrape_products(self, use_cache: bool = True, 
                       prefer_lightweight: bool = True) -> List[Dict[str, Any]]:
        """
        æŠ“å–äº§å“ - é€šç”¨æ–¹æ³•
        
        Args:
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            prefer_lightweight: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨è½»é‡çº§æ–¹æ³•
        
        Returns:
            äº§å“åˆ—è¡¨
        """
        # Step 1: Check cache
        if use_cache:
            cached_products = self._load_cache()
            if cached_products:
                print(f"âœ… Using {len(cached_products)} cached {self.category_name} products")
                return cached_products
        
        print(f"ðŸ” Starting to scrape AH.nl/{self.category_name} page...")
        
        # Step 2: Try lightweight method first
        if prefer_lightweight:
            products = self._try_lightweight_scrape()
            if products:
                self._save_cache(products)
                return products
        
        # Step 3: Fallback to Selenium
        print("ðŸŒ Using Selenium (fallback method)...")
        products = self._scrape_with_selenium()
        self._save_cache(products)
        return products
    
    def summarize_products(self, products: List[Dict[str, Any]]) -> str:
        """Summarize products - can be overridden by subclasses"""
        if not products:
            return f"No {self.category_name} products found"
        
        summary = f"ðŸ“Š AH.nl {self.category_name.capitalize()} Products Summary\n"
        summary += f"=" * 50 + "\n"
        summary += f"Total products: {len(products)}\n\n"
        
        # Show top 10 products
        summary += f"ðŸ”¥ Top 10 Products:\n"
        for i, product in enumerate(products[:10], 1):
            summary += f"  {i}. {product['title']} - {product.get('price', 'Unknown')}\n"
        
        return summary
    
    def __del__(self):
        """Cleanup"""
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass

