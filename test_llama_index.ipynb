{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0998227",
   "metadata": {},
   "source": [
    "# LlamaIndex Agent Testing Notebook\n",
    "\n",
    "This notebook requires Python 3.11.11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567cede1",
   "metadata": {},
   "source": [
    "## Setup env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5114a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "from langchain_community.llms import Ollama as OllamaLLM\n",
    "import os\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4529d4",
   "metadata": {},
   "source": [
    "## Setup boto3 connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0621a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID=\"#TODO\"\n",
    "AWS_SECRET_ACCESS_KEY=\"#TODO\"\n",
    "AWS_SESSION_TOKEN=\"#TODO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dev = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN,\n",
    "    region_name=\"eu-west-1\",\n",
    ")\n",
    "sagemaker_client = session_dev.client('sagemaker')\n",
    "s3_client = session_dev.client('s3')\n",
    "cloudwatch_client = session_dev.client('logs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d39786",
   "metadata": {},
   "source": [
    "## Setup ollama usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bdb172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gc/z5yp7b_519z5skvz2_fhk8ynxlwqtr/T/ipykernel_79709/4238583645.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm2 = OllamaLLM(model=\"llama3.1:8b\")\n"
     ]
    }
   ],
   "source": [
    "llm2 = OllamaLLM(model=\"llama3.1:8b\")\n",
    "llm = Ollama(model=\"llama3.1:8b\", request_timeout=120.0)\n",
    "# llm = BedrockLLM(\n",
    "#     model=\"llama3.1:8b\",\n",
    "#     region_name=\"eu-west-1\",\n",
    "#     endpoint_name=\"llama3.1:8b\",\n",
    "#     sagemaker_client=sagemaker_client,\n",
    "#     s3_client=s3_client,\n",
    "#     cloudwatch_client=cloudwatch_client,\n",
    "#     request_timeout=120.0,\n",
    "# )\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bbd2e",
   "metadata": {},
   "source": [
    "## Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99379796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_path(market:str, channel:str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Find the latest inference data \n",
    "    \"\"\"\n",
    "    s3_client = session_dev.client('s3')\n",
    "    \n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    latest_folder = None\n",
    "    latest_modified = None\n",
    "    bucket = \"dynamic-pricing-inference-616469646173-dev\"\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=f'dev/{market}/{channel}/', Delimiter='/'):\n",
    "        for cp in page.get('CommonPrefixes', []):\n",
    "            folder = cp['Prefix']\n",
    "            # List objects in the folder to get the latest modification time\n",
    "            objects = s3_client.list_objects_v2(Bucket=bucket, Prefix=folder)\n",
    "            if 'Contents' in objects:\n",
    "                folder_latest = max(obj['LastModified'] for obj in objects['Contents'])\n",
    "                if latest_modified is None or folder_latest > latest_modified:\n",
    "                    latest_modified = folder_latest\n",
    "                    latest_folder = folder\n",
    "\n",
    "    latest_modified = None\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=latest_folder, Delimiter='/'):\n",
    "        for cp in page.get('CommonPrefixes', []):\n",
    "            folder = cp['Prefix']\n",
    "            # List objects in the folder to get the latest modification time\n",
    "            objects = s3_client.list_objects_v2(Bucket=bucket, Prefix=folder)\n",
    "            if 'Contents' in objects:\n",
    "                folder_latest = max(obj['LastModified'] for obj in objects['Contents'])\n",
    "                if latest_modified is None or folder_latest > latest_modified:\n",
    "                    latest_modified = folder_latest\n",
    "                    latest_folder = folder\n",
    "\n",
    "    return \"s3://dynamic-pricing-inference-616469646173-dev/\"+latest_folder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d967b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data_give_market_channel(market: str, channel:str, query:str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    get a demand forecast for a given market, channel and article, discount\n",
    "    \"\"\"\n",
    "\n",
    "    # Download all files in the S3 folder to a local directory\n",
    "    temp_folder = f'./temp_folder_latest_{market}_{channel}'\n",
    "    if not os.path.exists(temp_folder):\n",
    "\n",
    "        s3_client = session_dev.client('s3')\n",
    "        path = find_latest_path(market, channel)+\"output/total/\"\n",
    "\n",
    "        if path is None:\n",
    "            print(f\"No path found for market {market} and channel {channel}\")\n",
    "            return None\n",
    "        else:\n",
    "            # Remove \"s3://\" and split bucket/key\n",
    "            s3_path = path.replace(\"s3://\", \"\")\n",
    "            bucket, key = s3_path.split(\"/\", 1)            \n",
    "            if not os.path.exists(temp_folder):\n",
    "                os.makedirs(temp_folder)\n",
    "            paginator = s3_client.get_paginator('list_objects_v2')\n",
    "            for page in paginator.paginate(Bucket=bucket, Prefix=key):\n",
    "                for obj in page.get('Contents', []):\n",
    "                    file_key = obj['Key']\n",
    "                    file_name = os.path.basename(file_key)\n",
    "                    if file_name:  # skip if it's a folder\n",
    "                        local_path = os.path.join(temp_folder, file_name)\n",
    "                        s3_client.download_file(bucket, file_key, local_path)\n",
    "    \n",
    "    data = pd.read_parquet(temp_folder)\n",
    "    # make data smaller \n",
    "    data = data[data['country']=='DE']\n",
    "    \n",
    "    df = SmartDataframe(data, config={\"llm\": llm2, \"verbose\": True})\n",
    "        \n",
    "    return df.chat(query)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb99fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-16 16:24:39 [INFO] Question: what is the sum of pred_combined_sales for IF8079 at different discount level?\n",
      "2025-05-16 16:24:39 [INFO] Running PandasAI with langchain_ollama-llm LLM...\n",
      "2025-05-16 16:24:39 [INFO] Prompt ID: 4e2a7c52-f611-4dc5-9594-3f0d6e04a2fb\n",
      "2025-05-16 16:24:39 [INFO] Executing Pipeline: GenerateChatPipeline\n",
      "2025-05-16 16:24:39 [INFO] Executing Step 0: ValidatePipelineInput\n",
      "2025-05-16 16:24:39 [INFO] Executing Step 1: CacheLookup\n",
      "2025-05-16 16:24:39 [INFO] Executing Step 2: PromptGeneration\n",
      "2025-05-16 16:24:40 [INFO] Using prompt: <dataframe>\n",
      "dfs[0]:86955x16\n",
      "country,date,article,discount,index,pred_causal_sales,pred_pred_sales,pred_combined_sales,pred_combined_probabilistic,pred_pred_probabilistic,pred_causal_probabilistic,campaign,voucher_campaign,voucher_markdown_proportion,voucher_redemption_rate,pred\n",
      "DE,2025-05-20,IF7804,0.35,107,0.7335095764349758,2.1851785570358624,1.7003444528932363,0.7483764060848429,0.8141304716715491,0.059171953973552655,no_campaign,no_campaign,0,0,0.45394612939322465\n",
      "DE,2025-05-19,ID4289,0.65,2596,4.436076525596529,2.402471542872889,3.579162633931832,0.36410204557713455,0.3802817763769146,0.34615036701511565,no_campaign,no_campaign,0,0,0.10060769820267575\n",
      "DE,2025-05-05,IF9084,0.55,278,0.5428009692887963,1.542745295203156,12.767704399777893,0.46051902825159335,0.09280285771416129,0.08857789484597861,no_campaign,no_campaign,0,0,0.6960527074187219\n",
      "</dataframe>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update this initial code:\n",
      "```python\n",
      "# TODO: import the required dependencies\n",
      "import pandas as pd\n",
      "\n",
      "# Write code here\n",
      "\n",
      "# Declare result var: \n",
      "type (possible values \"string\", \"number\", \"dataframe\", \"plot\"). Examples: { \"type\": \"string\", \"value\": f\"The highest salary is {highest_salary}.\" } or { \"type\": \"number\", \"value\": 125 } or { \"type\": \"dataframe\", \"value\": pd.DataFrame({...}) } or { \"type\": \"plot\", \"value\": \"temp_chart.png\" }\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "### QUERY\n",
      " what is the sum of pred_combined_sales for IF8079 at different discount level?\n",
      "\n",
      "Variable `dfs: list[pd.DataFrame]` is already declared.\n",
      "\n",
      "At the end, declare \"result\" variable as a dictionary of type and value.\n",
      "\n",
      "If you are asked to plot a chart, use \"matplotlib\" for charts, save as png.\n",
      "\n",
      "\n",
      "Generate python code and return full updated code:\n",
      "2025-05-16 16:24:40 [INFO] Executing Step 3: CodeGenerator\n",
      "2025-05-16 16:26:39 [INFO] Prompt used:\n",
      "            \n",
      "<dataframe>\n",
      "dfs[0]:86955x16\n",
      "country,date,article,discount,index,pred_causal_sales,pred_pred_sales,pred_combined_sales,pred_combined_probabilistic,pred_pred_probabilistic,pred_causal_probabilistic,campaign,voucher_campaign,voucher_markdown_proportion,voucher_redemption_rate,pred\n",
      "DE,2025-05-20,IF7804,0.35,107,0.7335095764349758,2.1851785570358624,1.7003444528932363,0.7483764060848429,0.8141304716715491,0.059171953973552655,no_campaign,no_campaign,0,0,0.45394612939322465\n",
      "DE,2025-05-19,ID4289,0.65,2596,4.436076525596529,2.402471542872889,3.579162633931832,0.36410204557713455,0.3802817763769146,0.34615036701511565,no_campaign,no_campaign,0,0,0.10060769820267575\n",
      "DE,2025-05-05,IF9084,0.55,278,0.5428009692887963,1.542745295203156,12.767704399777893,0.46051902825159335,0.09280285771416129,0.08857789484597861,no_campaign,no_campaign,0,0,0.6960527074187219\n",
      "</dataframe>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update this initial code:\n",
      "```python\n",
      "# TODO: import the required dependencies\n",
      "import pandas as pd\n",
      "\n",
      "# Write code here\n",
      "\n",
      "# Declare result var: \n",
      "type (possible values \"string\", \"number\", \"dataframe\", \"plot\"). Examples: { \"type\": \"string\", \"value\": f\"The highest salary is {highest_salary}.\" } or { \"type\": \"number\", \"value\": 125 } or { \"type\": \"dataframe\", \"value\": pd.DataFrame({...}) } or { \"type\": \"plot\", \"value\": \"temp_chart.png\" }\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "### QUERY\n",
      " what is the sum of pred_combined_sales for IF8079 at different discount level?\n",
      "\n",
      "Variable `dfs: list[pd.DataFrame]` is already declared.\n",
      "\n",
      "At the end, declare \"result\" variable as a dictionary of type and value.\n",
      "\n",
      "If you are asked to plot a chart, use \"matplotlib\" for charts, save as png.\n",
      "\n",
      "\n",
      "Generate python code and return full updated code:\n",
      "            \n",
      "2025-05-16 16:26:39 [INFO] Code generated:\n",
      "            ```\n",
      "            # Import the required dependencies\n",
      "import pandas as pd\n",
      "\n",
      "# Assuming dfs is already declared with the given DataFrame\n",
      "\n",
      "# Filter the data for article 'IF8079'\n",
      "article_df = dfs[0][dfs[0]['article'] == 'IF8079']\n",
      "\n",
      "# Group by discount level and calculate sum of pred_combined_sales\n",
      "discount_sum = article_df.groupby('discount')['pred_combined_sales'].sum()\n",
      "\n",
      "# Create a result dictionary with type as \"dataframe\" and value as the resulting DataFrame\n",
      "result = {\n",
      "    \"type\": \"dataframe\",\n",
      "    \"value\": discount_sum.to_frame().reset_index()\n",
      "}\n",
      "\n",
      "print(result)\n",
      "            ```\n",
      "            \n",
      "2025-05-16 16:26:39 [INFO] Executing Step 4: CachePopulation\n",
      "2025-05-16 16:26:39 [INFO] Executing Step 5: CodeCleaning\n",
      "2025-05-16 16:26:39 [INFO] \n",
      "Code running:\n",
      "```\n",
      "article_df = dfs[0][dfs[0]['article'] == 'IF8079']\n",
      "discount_sum = article_df.groupby('discount')['pred_combined_sales'].sum()\n",
      "result = {'type': 'dataframe', 'value': discount_sum.to_frame().reset_index()}\n",
      "print(result)\n",
      "        ```\n",
      "2025-05-16 16:26:39 [INFO] Executing Step 6: CodeExecution\n",
      "{'type': 'dataframe', 'value':     discount  pred_combined_sales\n",
      "0       0.00            80.266004\n",
      "1       0.05            93.720344\n",
      "2       0.10           108.485711\n",
      "3       0.15           124.493775\n",
      "4       0.20           141.631276\n",
      "5       0.25           159.737591\n",
      "6       0.30           178.604143\n",
      "7       0.35           197.975915\n",
      "8       0.40           217.555277\n",
      "9       0.45           237.008171\n",
      "10      0.50           255.972581\n",
      "11      0.55           274.069060\n",
      "12      0.60           290.912917\n",
      "13      0.65           306.127562\n",
      "14      0.70           319.358364}\n",
      "2025-05-16 16:26:39 [INFO] Executing Step 7: ResultValidation\n",
      "2025-05-16 16:26:39 [INFO] Answer: {'type': 'dataframe', 'value':     discount  pred_combined_sales\n",
      "0       0.00            80.266004\n",
      "1       0.05            93.720344\n",
      "2       0.10           108.485711\n",
      "3       0.15           124.493775\n",
      "4       0.20           141.631276\n",
      "5       0.25           159.737591\n",
      "6       0.30           178.604143\n",
      "7       0.35           197.975915\n",
      "8       0.40           217.555277\n",
      "9       0.45           237.008171\n",
      "10      0.50           255.972581\n",
      "11      0.55           274.069060\n",
      "12      0.60           290.912917\n",
      "13      0.65           306.127562\n",
      "14      0.70           319.358364}\n",
      "2025-05-16 16:26:39 [INFO] Executing Step 8: ResultParsing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount</th>\n",
       "      <th>pred_combined_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>80.266004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>93.720344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>108.485711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>124.493775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>141.631276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>159.737591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.30</td>\n",
       "      <td>178.604143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.35</td>\n",
       "      <td>197.975915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.40</td>\n",
       "      <td>217.555277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.45</td>\n",
       "      <td>237.008171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>255.972581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.55</td>\n",
       "      <td>274.069060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.60</td>\n",
       "      <td>290.912917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.65</td>\n",
       "      <td>306.127562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.70</td>\n",
       "      <td>319.358364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    discount  pred_combined_sales\n",
       "0       0.00            80.266004\n",
       "1       0.05            93.720344\n",
       "2       0.10           108.485711\n",
       "3       0.15           124.493775\n",
       "4       0.20           141.631276\n",
       "5       0.25           159.737591\n",
       "6       0.30           178.604143\n",
       "7       0.35           197.975915\n",
       "8       0.40           217.555277\n",
       "9       0.45           237.008171\n",
       "10      0.50           255.972581\n",
       "11      0.55           274.069060\n",
       "12      0.60           290.912917\n",
       "13      0.65           306.127562\n",
       "14      0.70           319.358364"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data_give_market_channel(\"EU\", \"inline\", \"what is the sum of pred_combined_sales for IF8079 at different discount level?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e7bce",
   "metadata": {},
   "source": [
    "## Define agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37dba4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent.workflow import ReActAgent\n",
    "from llama_index.core.workflow import Context\n",
    "import nest_asyncio\n",
    "from llama_index.core.agent.workflow import AgentStream, ToolCallResult\n",
    "\n",
    "# Define agent with tools\n",
    "agent = ReActAgent(tools=[find_latest_path, query_data_give_market_channel], llm=llm)\n",
    "\n",
    "# Create a context to store the conversation history/session state\n",
    "ctx = Context(agent)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def run_agent_query(query):\n",
    "    handler = agent.run(query, ctx=ctx)\n",
    "    async for ev in handler.stream_events():\n",
    "        if isinstance(ev, ToolCallResult):\n",
    "            print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
    "        if isinstance(ev, AgentStream):\n",
    "            print(f\"{ev.delta}\", end=\"\", flush=True)\n",
    "    return await handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d2cd56",
   "metadata": {},
   "source": [
    "## Test agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b94a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "\n",
      "Action: find_latest_path\n",
      "Action Input: {\"market\": \"EU\", \"channel\": \"inline\"}\n",
      "Call find_latest_path with {'market': 'EU', 'channel': 'inline'}\n",
      "Returned: s3://dynamic-pricing-inference-616469646173-dev/dev/EU/inline/general_2025-05-01_to_2025-05-31/2025-05-12-11-06-13-694/\n",
      "Thought: The observation indicates the path to the latest result for market=EU and channel=inline. I can use this information to answer the question.\n",
      "Answer: The latest result is located at s3://dynamic-pricing-inference-616469646173-dev/dev/EU/inline/general_2025-05-01_to_2025-05-31/2025-05-12-11-06-13-694/"
     ]
    }
   ],
   "source": [
    "# Just await directly:\n",
    "response = await run_agent_query(\"What is latest result for EU inline?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3239b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "\n",
      "Action: query_data_give_market_channel\n",
      "Action Input: {\"market\": \"EU\", \"channel\": \"inline\", \"query\": \"IF8079, 0.5\"}2025-05-21 14:57:08 [INFO] Question: IF8079, 0.5\n",
      "2025-05-21 14:57:09 [INFO] Running PandasAI with langchain_ollama-llm LLM...\n",
      "2025-05-21 14:57:09 [INFO] Prompt ID: c3aecd87-8172-4e60-9bdd-80827ef6e92a\n",
      "2025-05-21 14:57:09 [INFO] Executing Pipeline: GenerateChatPipeline\n",
      "2025-05-21 14:57:09 [INFO] Executing Step 0: ValidatePipelineInput\n",
      "2025-05-21 14:57:09 [INFO] Executing Step 1: CacheLookup\n",
      "2025-05-21 14:57:09 [INFO] Executing Step 2: PromptGeneration\n",
      "2025-05-21 14:57:09 [INFO] Using prompt: <dataframe>\n",
      "dfs[0]:86955x16\n",
      "country,date,article,discount,index,pred_causal_sales,pred_pred_sales,pred_combined_sales,pred_combined_probabilistic,pred_pred_probabilistic,pred_causal_probabilistic,campaign,voucher_campaign,voucher_markdown_proportion,voucher_redemption_rate,pred\n",
      "DE,2025-05-11,IG3378,0.25,4833,1.390681554112689,2.9705016536274935,13.134131473839654,0.5764697347362298,0.16804110991853602,0.6217027933900882,no_campaign,no_campaign,0,0,0.37499265273895654\n",
      "DE,2025-05-06,IE7345,0.45,1678,1.5027900995420356,2.91530201773602,3.809890400904507,0.6204946414710117,0.053208306748206285,0.010742022525847716,no_campaign,no_campaign,0,0,0.6687902064638808\n",
      "DE,2025-05-29,ID4593,0.0,489,0.3353560581404538,2.28449255343656,3.4814832385704415,0.8446757502785156,0.013448540775286753,0.12521033108798102,no_campaign,no_campaign,0,0,0.7263034791847246\n",
      "</dataframe>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update this initial code:\n",
      "```python\n",
      "# TODO: import the required dependencies\n",
      "import pandas as pd\n",
      "\n",
      "# Write code here\n",
      "\n",
      "# Declare result var: \n",
      "type (possible values \"string\", \"number\", \"dataframe\", \"plot\"). Examples: { \"type\": \"string\", \"value\": f\"The highest salary is {highest_salary}.\" } or { \"type\": \"number\", \"value\": 125 } or { \"type\": \"dataframe\", \"value\": pd.DataFrame({...}) } or { \"type\": \"plot\", \"value\": \"temp_chart.png\" }\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "### QUERY\n",
      " IF8079, 0.5\n",
      "\n",
      "Variable `dfs: list[pd.DataFrame]` is already declared.\n",
      "\n",
      "At the end, declare \"result\" variable as a dictionary of type and value.\n",
      "\n",
      "If you are asked to plot a chart, use \"matplotlib\" for charts, save as png.\n",
      "\n",
      "\n",
      "Generate python code and return full updated code:\n",
      "2025-05-21 14:57:09 [INFO] Executing Step 3: CodeGenerator\n",
      "2025-05-21 15:00:30 [INFO] Prompt used:\n",
      "            \n",
      "<dataframe>\n",
      "dfs[0]:86955x16\n",
      "country,date,article,discount,index,pred_causal_sales,pred_pred_sales,pred_combined_sales,pred_combined_probabilistic,pred_pred_probabilistic,pred_causal_probabilistic,campaign,voucher_campaign,voucher_markdown_proportion,voucher_redemption_rate,pred\n",
      "DE,2025-05-11,IG3378,0.25,4833,1.390681554112689,2.9705016536274935,13.134131473839654,0.5764697347362298,0.16804110991853602,0.6217027933900882,no_campaign,no_campaign,0,0,0.37499265273895654\n",
      "DE,2025-05-06,IE7345,0.45,1678,1.5027900995420356,2.91530201773602,3.809890400904507,0.6204946414710117,0.053208306748206285,0.010742022525847716,no_campaign,no_campaign,0,0,0.6687902064638808\n",
      "DE,2025-05-29,ID4593,0.0,489,0.3353560581404538,2.28449255343656,3.4814832385704415,0.8446757502785156,0.013448540775286753,0.12521033108798102,no_campaign,no_campaign,0,0,0.7263034791847246\n",
      "</dataframe>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update this initial code:\n",
      "```python\n",
      "# TODO: import the required dependencies\n",
      "import pandas as pd\n",
      "\n",
      "# Write code here\n",
      "\n",
      "# Declare result var: \n",
      "type (possible values \"string\", \"number\", \"dataframe\", \"plot\"). Examples: { \"type\": \"string\", \"value\": f\"The highest salary is {highest_salary}.\" } or { \"type\": \"number\", \"value\": 125 } or { \"type\": \"dataframe\", \"value\": pd.DataFrame({...}) } or { \"type\": \"plot\", \"value\": \"temp_chart.png\" }\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "### QUERY\n",
      " IF8079, 0.5\n",
      "\n",
      "Variable `dfs: list[pd.DataFrame]` is already declared.\n",
      "\n",
      "At the end, declare \"result\" variable as a dictionary of type and value.\n",
      "\n",
      "If you are asked to plot a chart, use \"matplotlib\" for charts, save as png.\n",
      "\n",
      "\n",
      "Generate python code and return full updated code:\n",
      "            \n",
      "2025-05-21 15:00:30 [INFO] Code generated:\n",
      "            ```\n",
      "            # TODO: import the required dependencies\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Write code here\n",
      "\n",
      "# Filter dataframe where article is IF8079 and discount is 0.5\n",
      "filtered_df = [df[df['article'] == 'IF8079' and df['discount'] == 0.5] for df in dfs]\n",
      "\n",
      "# Combine the filtered dataframes into one\n",
      "combined_df = pd.concat(filtered_df, ignore_index=True)\n",
      "\n",
      "# Drop any rows with missing values (in case there are none)\n",
      "combined_df.dropna(inplace=True)\n",
      "\n",
      "# If the dataframe is not empty\n",
      "if not combined_df.empty:\n",
      "    # Calculate the average pred_combined_sales for each row\n",
      "    avg_pred_combined_sales = combined_df['pred_combined_sales'].mean()\n",
      "\n",
      "    # Create a string to display the result\n",
      "    result_value = f\"The average predicted combined sales for IF8079 with discount 0.5 is {avg_pred_combined_sales:.2f}\"\n",
      "\n",
      "    # Declare result var: \n",
      "    result = {\n",
      "        \"type\": \"string\",\n",
      "        \"value\": result_value\n",
      "    }\n",
      "\n",
      "else:\n",
      "    # If the dataframe is empty, create a default string to display the result\n",
      "    result_value = f\"No data available for IF8079 with discount 0.5\"\n",
      "\n",
      "    # Declare result var: \n",
      "    result = {\n",
      "        \"type\": \"string\",\n",
      "        \"value\": result_value\n",
      "    }\n",
      "            ```\n",
      "            \n",
      "2025-05-21 15:00:30 [INFO] Executing Step 4: CachePopulation\n",
      "2025-05-21 15:00:30 [INFO] Executing Step 5: CodeCleaning\n",
      "2025-05-21 15:00:30 [INFO] \n",
      "Code running:\n",
      "```\n",
      "filtered_df = [df[df['article'] == 'IF8079' and df['discount'] == 0.5] for df in dfs]\n",
      "combined_df = pd.concat(filtered_df, ignore_index=True)\n",
      "combined_df.dropna(inplace=True)\n",
      "if not combined_df.empty:\n",
      "    avg_pred_combined_sales = combined_df['pred_combined_sales'].mean()\n",
      "    result_value = f'The average predicted combined sales for IF8079 with discount 0.5 is {avg_pred_combined_sales:.2f}'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "else:\n",
      "    result_value = f'No data available for IF8079 with discount 0.5'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "        ```\n",
      "2025-05-21 15:00:30 [INFO] Executing Step 6: CodeExecution\n",
      "2025-05-21 15:00:30 [ERROR] Failed with error: Traceback (most recent call last):\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
      "    result = self.execute_code(code_to_run, code_context)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandasai/pipelines/chat/code_execution.py\", line 171, in execute_code\n",
      "    exec(code, environment)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <listcomp>\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandas/core/generic.py\", line 1527, in __nonzero__\n",
      "    raise ValueError(\n",
      "ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "2025-05-21 15:00:30 [WARNING] Failed to execute code retrying with a correction framework [retry number: 1]\n",
      "2025-05-21 15:00:30 [INFO] Executing Pipeline: ErrorCorrectionPipeline\n",
      "2025-05-21 15:00:30 [INFO] Executing Step 0: ErrorPromptGeneration\n",
      "2025-05-21 15:00:30 [INFO] Using prompt: <dataframe>\n",
      "dfs[0]:86955x16\n",
      "country,date,article,discount,index,pred_causal_sales,pred_pred_sales,pred_combined_sales,pred_combined_probabilistic,pred_pred_probabilistic,pred_causal_probabilistic,campaign,voucher_campaign,voucher_markdown_proportion,voucher_redemption_rate,pred\n",
      "DE,2025-05-11,IG3378,0.25,4833,1.390681554112689,2.9705016536274935,13.134131473839654,0.5764697347362298,0.16804110991853602,0.6217027933900882,no_campaign,no_campaign,0,0,0.37499265273895654\n",
      "DE,2025-05-06,IE7345,0.45,1678,1.5027900995420356,2.91530201773602,3.809890400904507,0.6204946414710117,0.053208306748206285,0.010742022525847716,no_campaign,no_campaign,0,0,0.6687902064638808\n",
      "DE,2025-05-29,ID4593,0.0,489,0.3353560581404538,2.28449255343656,3.4814832385704415,0.8446757502785156,0.013448540775286753,0.12521033108798102,no_campaign,no_campaign,0,0,0.7263034791847246\n",
      "</dataframe>\n",
      "\n",
      "\n",
      "The user asked the following question:\n",
      "### QUERY\n",
      " IF8079, 0.5\n",
      "\n",
      "You generated this python code:\n",
      "filtered_df = [df[df['article'] == 'IF8079' and df['discount'] == 0.5] for df in dfs]\n",
      "combined_df = pd.concat(filtered_df, ignore_index=True)\n",
      "combined_df.dropna(inplace=True)\n",
      "if not combined_df.empty:\n",
      "    avg_pred_combined_sales = combined_df['pred_combined_sales'].mean()\n",
      "    result_value = f'The average predicted combined sales for IF8079 with discount 0.5 is {avg_pred_combined_sales:.2f}'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "else:\n",
      "    result_value = f'No data available for IF8079 with discount 0.5'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "\n",
      "It fails with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
      "    result = self.execute_code(code_to_run, code_context)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandasai/pipelines/chat/code_execution.py\", line 171, in execute_code\n",
      "    exec(code, environment)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <listcomp>\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandas/core/generic.py\", line 1527, in __nonzero__\n",
      "    raise ValueError(\n",
      "ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "\n",
      "Fix the python code above and return the new python code:\n",
      "2025-05-21 15:00:30 [INFO] Executing Step 1: CodeGenerator\n",
      "2025-05-21 15:03:25 [INFO] Prompt used:\n",
      "            \n",
      "<dataframe>\n",
      "dfs[0]:86955x16\n",
      "country,date,article,discount,index,pred_causal_sales,pred_pred_sales,pred_combined_sales,pred_combined_probabilistic,pred_pred_probabilistic,pred_causal_probabilistic,campaign,voucher_campaign,voucher_markdown_proportion,voucher_redemption_rate,pred\n",
      "DE,2025-05-11,IG3378,0.25,4833,1.390681554112689,2.9705016536274935,13.134131473839654,0.5764697347362298,0.16804110991853602,0.6217027933900882,no_campaign,no_campaign,0,0,0.37499265273895654\n",
      "DE,2025-05-06,IE7345,0.45,1678,1.5027900995420356,2.91530201773602,3.809890400904507,0.6204946414710117,0.053208306748206285,0.010742022525847716,no_campaign,no_campaign,0,0,0.6687902064638808\n",
      "DE,2025-05-29,ID4593,0.0,489,0.3353560581404538,2.28449255343656,3.4814832385704415,0.8446757502785156,0.013448540775286753,0.12521033108798102,no_campaign,no_campaign,0,0,0.7263034791847246\n",
      "</dataframe>\n",
      "\n",
      "\n",
      "The user asked the following question:\n",
      "### QUERY\n",
      " IF8079, 0.5\n",
      "\n",
      "You generated this python code:\n",
      "filtered_df = [df[df['article'] == 'IF8079' and df['discount'] == 0.5] for df in dfs]\n",
      "combined_df = pd.concat(filtered_df, ignore_index=True)\n",
      "combined_df.dropna(inplace=True)\n",
      "if not combined_df.empty:\n",
      "    avg_pred_combined_sales = combined_df['pred_combined_sales'].mean()\n",
      "    result_value = f'The average predicted combined sales for IF8079 with discount 0.5 is {avg_pred_combined_sales:.2f}'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "else:\n",
      "    result_value = f'No data available for IF8079 with discount 0.5'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "\n",
      "It fails with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
      "    result = self.execute_code(code_to_run, code_context)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandasai/pipelines/chat/code_execution.py\", line 171, in execute_code\n",
      "    exec(code, environment)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <listcomp>\n",
      "  File \"/Users/liuqi7/Library/Caches/pypoetry/virtualenvs/agent-test-llamaindex-LgRdK7YQ-py3.11/lib/python3.11/site-packages/pandas/core/generic.py\", line 1527, in __nonzero__\n",
      "    raise ValueError(\n",
      "ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "\n",
      "Fix the python code above and return the new python code:\n",
      "            \n",
      "2025-05-21 15:03:25 [INFO] Code generated:\n",
      "            ```\n",
      "            filtered_df = [df[(df['article'] == 'IF8079') & (df['discount'] == 0.5)] for df in dfs]\n",
      "combined_df = pd.concat(filtered_df, ignore_index=True)\n",
      "combined_df.dropna(inplace=True)\n",
      "if not combined_df.empty:\n",
      "    avg_pred_combined_sales = combined_df['pred_combined_sales'].mean()\n",
      "    result_value = f'The average predicted combined sales for IF8079 with discount 0.5 is {avg_pred_combined_sales:.2f}'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "else:\n",
      "    result_value = f'No data available for IF8079 with discount 0.5'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "            ```\n",
      "            \n",
      "2025-05-21 15:03:25 [INFO] Executing Step 2: CodeCleaning\n",
      "2025-05-21 15:03:25 [INFO] \n",
      "Code running:\n",
      "```\n",
      "filtered_df = [df[(df['article'] == 'IF8079') & (df['discount'] == 0.5)] for df in dfs]\n",
      "combined_df = pd.concat(filtered_df, ignore_index=True)\n",
      "combined_df.dropna(inplace=True)\n",
      "if not combined_df.empty:\n",
      "    avg_pred_combined_sales = combined_df['pred_combined_sales'].mean()\n",
      "    result_value = f'The average predicted combined sales for IF8079 with discount 0.5 is {avg_pred_combined_sales:.2f}'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "else:\n",
      "    result_value = f'No data available for IF8079 with discount 0.5'\n",
      "    result = {'type': 'string', 'value': result_value}\n",
      "        ```\n",
      "2025-05-21 15:03:25 [INFO] Executing Step 7: ResultValidation\n",
      "2025-05-21 15:03:25 [INFO] Answer: {'type': 'string', 'value': 'The average predicted combined sales for IF8079 with discount 0.5 is 8.26'}\n",
      "2025-05-21 15:03:26 [INFO] Executing Step 8: ResultParsing\n",
      "\n",
      "Call query_data_give_market_channel with {'market': 'EU', 'channel': 'inline', 'query': 'IF8079, 0.5'}\n",
      "Returned: The average predicted combined sales for IF8079 with discount 0.5 is 8.26\n",
      "2025-05-21 15:04:34 [INFO] HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "Thought: I can answer without using any more tools.\n",
      "Answer: The predicted combined sales for article IF8079 at a discount level of 0.5 in the EU market through inline channel is approximately 8.26 units."
     ]
    }
   ],
   "source": [
    "# Just await directly:\n",
    "response = await run_agent_query(\"Can you give me prediction for combined sales for article IF8079 at discount 0.5 level in EU inline?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813197a",
   "metadata": {},
   "source": [
    "## Simply frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO RUN STREAMLIT HOST LOCALLY\n",
    "# Export this entire notebook into app.py \n",
    "# !streamlit run app.py\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "import asyncio\n",
    "\n",
    "st.title(\"LlamaIndex Agent UI\")\n",
    "\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "\n",
    "user_input = st.text_input(\"Ask a question to the agent:\")\n",
    "\n",
    "if st.button(\"Send\") and user_input:\n",
    "    st.session_state.chat_history.append((\"User\", user_input))\n",
    "\n",
    "    # Use the same run_agent_query function directly\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "    except RuntimeError:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "\n",
    "    response_text = loop.run_until_complete(run_agent_query(user_input))\n",
    "    st.session_state.chat_history.append((\"Agent\", response_text))\n",
    "\n",
    "for speaker, text in st.session_state.chat_history:\n",
    "    st.markdown(f\"**{speaker}:** {text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
